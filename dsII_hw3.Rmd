---
title: "Data Science II: HW3"
author:
- "Shayne Estill"
date: "04/01/2025"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

```

# Libraries

```{r}

# Load libraries
library(tidyverse)
library(caret)
library(ggplot2)  
library(patchwork)
library(corrplot)
library(mgcv)
library(tidymodels)
library(earth)
library(boot) 
library(table1)
library(knitr)
library(pls)
library(glmnet)
library(pROC)
library(pdp)
library(MASS)



```

In this problem, you will develop a model to predict whether a given car gets high or
low gas mileage based on the dataset “auto.csv”. The dataset contains 392 observations.
The response variable is “mpg cat”, which indicates whether the miles per gallon of a car
is high or low. The predictors include both continuous and categorical variables:
• cylinders: Number of cylinders between 4 and 8
• displacement: Engine displacement (cu. inches)
• horsepower: Engine horsepower
• weight: Vehicle weight (lbs.)
• acceleration: Time to accelerate from 0 to 60 mph (sec.)
• year: Model year (modulo 100)
• origin: Origin of car (1. American, 2. European, 3. Japanese)

Split the dataset into two parts: training data (70%) and test data (30%).

```{r}
# Load auto data
auto_data = read_csv(file = "/Users/shayneestill/Desktop/Data Science II/dsII_hw3/auto.csv", 
                        na = c("NA", ".", "")) |>
                        janitor::clean_names() |>
  mutate(mpg_cat = ifelse(mpg_cat == "high", 1, 0))

drop_na(auto_data)
set.seed(0401)

data_split <- initial_split(auto_data, prop = 0.8)

ctrl1 <- trainControl(method = "cv", number = 10)

# Extract the training and test data
training_data <- training(data_split)
testing_data <- testing(data_split)

```


(a) Perform logistic regression analysis. Are there redundant predictors in your model?
If so, identify them. If there are none, please provide an explanation.

```{r}
set.seed(0401)

glm.fit <- glm(mpg_cat ~ .,
data = training_data,
family = binomial(link = "logit"))

summary(glm.fit)
```

Yes, there are redundant predictors in this model. cylinders, displacement, horsepower, acceleration, and origin all have a p-value less than 0.05 and are not statistically significant. 

```{r}
# predict probabilities for test data
set.seed(0401)

test.pred.prob <- predict(glm.fit, newdata = testing_data,
type = "response")

# convert probabilities to binary predictions using a 0.5 cutoff
test.pred <- rep(0, length(test.pred.prob))
test.pred[test.pred.prob > 0.5] <- 1

# generate confusion matrix
confusionMatrix(data = as.factor(test.pred),
reference = as.factor(testing_data$mpg_cat),
positive = "1")
```

```{r}
set.seed(0401)
# generate ROC curve for the logistic regression model
roc.glm <- roc(testing_data$mpg_cat, test.pred.prob)

# plot the ROC curve and the smoothed ROC curve
plot(roc.glm, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(roc.glm), col = 4, add = TRUE)
```

AUC = 0.975. The larger the AUC, the better the classifier. The logistic regression is considered very good. 


(b) Train a multivariate adaptive regression spline (MARS) model. Does the MARS
model improve prediction performance compared to logistic regression?

```{r}
set.seed(0401)

training_data$mpg_cat <- factor(training_data$mpg_cat, levels = c(0, 1), labels = c("low", "high"))

ctrl <- trainControl(method = "cv", number = 10,
summaryFunction = twoClassSummary,
classProbs = TRUE)

```


```{r}
set.seed(0401)

model.mars <- train(mpg_cat ~ .,
data = training_data,
method = "earth",
tuneGrid = expand.grid(degree = 1:4,
nprune = 2:20),
metric = "ROC",
trControl = ctrl)

plot(model.mars)
summary(model.mars)

```

```{r}
coef(model.mars$finalModel)
```

```{r}
prob.mars <- predict(model.mars, newdata = testing_data,
type = "prob")

# convert probabilities to binary predictions using a 0.5 cutoff
pred.mars <- rep("high", length(prob.mars))
pred.mars[prob.mars > 0.5] = "low"

# generate confusion matrix
confusionMatrix(data = as.factor(pred.mars),
reference = testing_data$mpg_cat,
positive = "low")
```


MARS improves? model prediction compared to logistic regression because ...

(c) Perform linear discriminant analysis using the training data. Plot the linear discriminant(s).
```{r}
lda.fit <- lda(mpg_cat~., data = training_data)
# Plot the histogram of the discriminant variables (Z-variable,Z = aˆT*X) for each group
plot(lda.fit)

A <- lda.fit$scaling
```

```{r}
head(predict(lda.fit)$x)
```

```{r}
mean(predict(lda.fit)$x)
```

```{r}
lda.pred <- predict(lda.fit, newdata = testing_data)
head(lda.pred$posterior)
```


```{r}
set.seed(0401)

ctrl <- trainControl(method = "repeatedcv", repeats = 5,
summaryFunction = twoClassSummary,
classProbs = TRUE)

# train LDA model with CV
set.seed(0401)
model.lda <- train(x = training_data[, 1:8],
y = training_data$mpg_cat,
method = "lda",
metric = "ROC",
trControl = ctrl)

# predict probabilities for test data
lda.pred2 <- predict(model.lda, newdata = testing_data, type = "prob")
head(lda.pred2)
```


(d) Which model will you choose to predict the response variable? Plot its ROC curve
and report the AUC. Next, select a probability threshold to classify observations and
compute the confusion matrix. Briefly interpret what the confusion matrix indicates
about your model’s performance.

```{r}
res <- resamples(list(GLM = model.glm,
LDA = lda.fit,
MARS = model.mars))
summary(res)
```

